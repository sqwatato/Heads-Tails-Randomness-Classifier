{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting whether a sequence of heads or tails of length 20 was computer generated or human written\n",
    "#### Recurrent Neural Network:\n",
    "##### Hopefully can use previous H/T to help with predictions\n",
    "##### I made the H/T into a tiny word vector so we'll see hehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense, GRU, LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train, y_train, X_test, y_test = util.load_rnn_data()\n",
    "print(\"X_train\", X_train[:5])\n",
    "print(\"y_train\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Simple RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(30, input_shape=(20,1,), activation=\"relu\"))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(20, input_shape=(20,1,), activation=\"relu\"))\n",
    "model2.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GRU model\n",
    "model3 = Sequential()\n",
    "model3.add(GRU(20, input_shape=(20,1,), activation=\"relu\"))\n",
    "model3.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "rnn = model.fit(X_train, y_train, validation_data = (X_test,y_test), batch_size=20, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "lstm = model2.fit(X_train, y_train, validation_data = (X_test,y_test), batch_size=20, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "gru = model3.fit(X_train, y_train, validation_data = (X_test,y_test), batch_size=20, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Rounding sigmoid output for classification\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(round(y_pred[i][0]))\n",
    "pred = np.array(pred)\n",
    "print(pred)\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Rounding sigmoid output for classification\n",
    "pred2 = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred2.append(round(y_pred[i][0]))\n",
    "pred2 = np.array(pred2)\n",
    "print(pred2)\n",
    "\n",
    "# Get Predictions\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "# Rounding sigmoid output for classification\n",
    "pred3 = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred3.append(round(y_pred[i][0]))\n",
    "pred3 = np.array(pred3)\n",
    "print(pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACY!!!\n",
    "plt.plot(rnn.history['accuracy'])\n",
    "plt.plot(rnn.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "# Idk why test is that much better lol\n",
    "# Still seems like it's going up but cut at 15 epochs so my computer doesn't die :(\n",
    "# Plot loss\n",
    "plt.plot(rnn.history['loss']) \n",
    "plt.plot(rnn.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, pred, average='binary')\n",
    "a = accuracy_score(pred,y_test)\n",
    "print('Accuracy is:', a*100)\n",
    "print(\"Precision:\", np.round(precision, 2))\n",
    "print(\"Recall:\", np.round(recall, 2))\n",
    "print(\"F-Score:\", np.round(fscore, 2))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACY!!!\n",
    "plt.plot(lstm.history['accuracy'])\n",
    "plt.plot(lstm.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lstm.history['loss']) \n",
    "plt.plot(lstm.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, pred2, average='binary')\n",
    "a = accuracy_score(pred2,y_test)\n",
    "print('Accuracy is:', a*100)\n",
    "print(\"Precision:\", np.round(precision, 2))\n",
    "print(\"Recall:\", np.round(recall, 2))\n",
    "print(\"F-Score:\", np.round(fscore, 2))\n",
    "cm = confusion_matrix(y_test, pred2)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACY!!!\n",
    "plt.plot(gru.history['accuracy'])\n",
    "plt.plot(gru.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(gru.history['loss']) \n",
    "plt.plot(gru.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, pred3, average='binary')\n",
    "a = accuracy_score(pred3,y_test)\n",
    "print('Accuracy is:', a*100)\n",
    "print(\"Precision:\", np.round(precision, 2))\n",
    "print(\"Recall:\", np.round(recall, 2))\n",
    "print(\"F-Score:\", np.round(fscore, 2))\n",
    "cm = confusion_matrix(y_test, pred3)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.predict_rnn(util.random_coinflip(), model, model2, model3)\n",
    "#                 hhhhhhhhhhhhhhhhhhhh\n",
    "util.predict_rnn(\"httthhthhthttthhttth\", model, model2, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/rnn\")\n",
    "model2.save(\"./models/lstm\")\n",
    "model3.save(\"./models/gru\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0f6d8254eb83d39449414d1a3d23136d65ed16273f9b93f72c8276e237615e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
